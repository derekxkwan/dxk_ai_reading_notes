---
title: "Emergent Musical Properties of a Transformer Under Contrastive Self-Supervised Learning"
date: 2026-02-06T16:05:06-08:00
authors: ["Yuexuan Kong", "Gabriel Meseguer-Brocal", "Vincent Lostanlen", "Mathieu Lagrange", "Romain Hennequin"]
year: 2025
tags: ["music theory", "music", "beat tracking", "chord estimation", "vit", "attention maps", "transformer", "audio", "log-mel spectrogram", "self-similarity matrix"]
categories: ["deep learning", "self-supervised"]
paper_url: ""
doi: "10.5281/zenodo.17706383"
paper_src: "Proceedings of the 26th International Society for Music Information Retrieval Conference"
bibkey: "kong2025"
math: true
draft: false
---

## Summary
Trains a small ViT with 1-D spectrograms to investigate temporality of embedding tokens from using constrastive learning (temperate cross-entropy loss). Comparable performance with JEPA and better than CLMR on beat tracking with sequence tokens. Study of attention maps shows onsets at lower layers (SSM). Best performance using stacked tokens (compared to last token and random init) for downstream tasks of music tagging, key detection, beat tracking, and chord prediction.

## Key Contributions
Showed encoding of time sensitive events in sequence tokens using contrastive learning.

## Limitations and Future Work
Comprehensive analysis of layers (just did every 3). Weighted sum of all layers for downstream tasks experiments not done. Study of just supervised pretraining on all tasks is future work.

## Key Equations


## Other Notes
