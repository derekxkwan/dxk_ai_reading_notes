---
title: "Do Music Generation Models Encode Music Theory?"
date: 2026-02-02T13:45:57-08:00
authors: ["Megan Wei", "Michael Freeman", "Chris Donahue", "Chen Sun"]
year: 2024
tags: ["probing", "music", "midi", "concept datasets", "symbolic music to audio", "rhythmic (music)", "mlp", "symbolic music", "representation leveraging", "music theory"]
categories: ["xai", "deep learning", "classification"]
paper_url: "https://doi.org/10.5281/zenodo.14877427"
doi: "10.5281/zenodo.14877427"
paper_src: "Proceedings of the 25th International Society for Music Information Retrieval Conference"
bibkey: "wei_music_2024"
math: true
draft: false
---

## Summary
Creates MIDI datasets centered around music theory concepts (chords, chord progressions, tempi, time signatures, scales, etc.) which are sonified into WAVs and fed into text-music-generative models MusicGen and Jukebox. Activations are then used to train 2-layers MLPs and class accuracy corresponds to "learning" a concept.

## Key Contributions

## Limitations and Future Work

## Key Equations

## Other Notes

